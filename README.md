# ğŸš€ RAG Microservicio

Microservicio completo para **Retrieval-Augmented Generation (RAG)** que permite subir documentos PDF, crear bases vectoriales automÃ¡ticamente y realizar consultas inteligentes usando modelos de Hugging Face.

## ğŸ¯ CaracterÃ­sticas Principales

- **ğŸ“„ Procesamiento de PDFs**: Carga y procesa documentos PDF automÃ¡ticamente
- **ğŸ” Base Vectorial**: Crea y mantiene Ã­ndices vectoriales usando FAISS
- **ğŸ¤– IA MultilingÃ¼e**: Soporte para consultas en mÃºltiples idiomas
- **ğŸ“Š API REST Completa**: Endpoints JSON para todas las operaciones
- **ğŸ·ï¸ Namespaces**: OrganizaciÃ³n de documentos por categorÃ­as
- **âš¡ Consultas en Lote**: Procesamiento de mÃºltiples consultas simultÃ¡neas
- **ğŸ”„ Auto-sincronizaciÃ³n**: DetecciÃ³n automÃ¡tica de nuevos PDFs
- **ğŸ“ˆ Monitoreo**: Health checks y mÃ©tricas de estado
- **ğŸ³ Docker Ready**: Containerizado y listo para producciÃ³n

## ğŸ› ï¸ TecnologÃ­as

- **FastAPI**: Framework web moderno y rÃ¡pido
- **LangChain**: OrquestaciÃ³n de modelos de IA
- **Hugging Face**: Modelos de embeddings y generaciÃ³n
- **FAISS**: BÃºsqueda vectorial eficiente
- **SQLite**: Base de datos para metadatos
- **Docker**: ContainerizaciÃ³n para despliegue

## ğŸš€ Inicio RÃ¡pido

### 1. ConfiguraciÃ³n del Entorno

```bash
# Clonar el repositorio
git clone <repository-url>
cd rag-microservice

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# o en Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. ConfiguraciÃ³n

```bash
# Copiar template de configuraciÃ³n
cp .env.template .env

# Editar .env y agregar tu token de Hugging Face
HUGGINGFACEHUB_API_TOKEN=tu_token_aqui
```

### 3. Ejecutar el Microservicio

```bash
# Modo desarrollo
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# O usar el script de inicio
./scripts/start.sh  # Linux/Mac
# o en Windows: .\scripts\start.ps1
```

### 4. Con Docker

```bash
# Construir y ejecutar
docker-compose up --build

# Solo ejecutar (si ya estÃ¡ construido)
docker-compose up -d
```

## ğŸ“‹ API Endpoints

### ğŸ” Estado y Salud

```http
GET /health
GET /status
GET /namespaces
```

### ğŸ“„ GestiÃ³n de Documentos

```http
# Subir documento PDF
POST /documents/upload
Content-Type: multipart/form-data

{
  "file": <archivo_pdf>,
  "namespace": "mi_namespace",
  "description": "DescripciÃ³n opcional"
}
```

```http
# Sincronizar PDFs desde directorio
POST /documents/sync
```

### ğŸ¤– Consultas RAG

```http
# Consulta simple
POST /query
Content-Type: application/json

{
  "query": "Â¿CuÃ¡les son los puntos principales?",
  "namespace": "compromidos",
  "max_results": 5,
  "temperature": 0.7,
  "max_tokens": 600
}
```

```http
# Consultas en lote
POST /query/batch
Content-Type: application/json

{
  "queries": [
    "Primera pregunta",
    "Segunda pregunta"
  ],
  "namespace": "compromidos",
  "max_results": 3
}
```

### âš™ï¸ AdministraciÃ³n

```http
# Reconstruir Ã­ndice vectorial
POST /vectorstore/rebuild?namespace=mi_namespace
```

## ğŸ“Š Ejemplos de Uso

### Subir un Documento

```python
import requests

# Subir PDF
with open('documento.pdf', 'rb') as f:
    files = {'file': ('documento.pdf', f, 'application/pdf')}
    data = {'namespace': 'documentos', 'description': 'Mi documento'}
    
    response = requests.post(
        'http://localhost:8000/documents/upload',
        files=files,
        data=data
    )
    
print(response.json())
```

### Realizar Consulta

```python
import requests

# Consulta RAG
query_data = {
    "query": "Resume los puntos mÃ¡s importantes",
    "namespace": "documentos",
    "max_results": 5,
    "temperature": 0.7
}

response = requests.post(
    'http://localhost:8000/query',
    json=query_data
)

result = response.json()
print(f"Respuesta: {result['answer']}")
print(f"Fuentes utilizadas: {len(result['sources_used'])}")
```

### Consultas en Lote

```python
import requests

# MÃºltiples consultas
batch_data = {
    "queries": [
        "Â¿CuÃ¡l es el tema principal?",
        "Â¿QuÃ© recomendaciones se mencionan?",
        "Resume en 3 puntos clave"
    ],
    "namespace": "documentos",
    "max_results": 3
}

response = requests.post(
    'http://localhost:8000/query/batch',
    json=batch_data
)

results = response.json()
for i, result in enumerate(results['results']):
    print(f"Consulta {i+1}: {result['answer'][:100]}...")
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno Principales

```bash
# Modelos de IA
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
GENERATION_MODEL=mistralai/Mistral-7B-Instruct-v0.3

# ConfiguraciÃ³n de chunks
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# ParÃ¡metros de generaciÃ³n
TEMPERATURE=0.7
MAX_TOKENS=600
RETRIEVAL_K=5
```

### Modelos Recomendados

#### Para Desarrollo (MÃ¡s RÃ¡pido)
```bash
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
GENERATION_MODEL=google/flan-t5-small
```

#### Para ProducciÃ³n (MÃ¡s Preciso)
```bash
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
GENERATION_MODEL=mistralai/Mistral-7B-Instruct-v0.3
```

## ğŸ§ª Pruebas

### Ejecutar Suite de Pruebas

```bash
# Pruebas completas
python test_microservice.py

# Solo pruebas de API JSON
python test_microservice.py --json-only

# Pruebas con URL personalizada
python test_microservice.py --url http://mi-servidor:8000
```

### Verificar Funcionamiento

```bash
# Health check
curl http://localhost:8000/health

# Estado del servicio
curl http://localhost:8000/status

# Listar namespaces
curl http://localhost:8000/namespaces
```

## ğŸ³ Despliegue en ProducciÃ³n

### Docker Compose

```bash
# Configurar variables de producciÃ³n
cp .env.template .env
# Editar .env con configuraciÃ³n de producciÃ³n

# Desplegar
docker-compose -f docker-compose.production.yml up -d
```

### Con Reverse Proxy (Nginx)

```bash
# Activar perfil de producciÃ³n con proxy
docker-compose --profile production up -d
```

### Recursos Recomendados

- **CPU**: MÃ­nimo 2 cores, recomendado 4+ cores
- **RAM**: MÃ­nimo 4GB, recomendado 8GB+ para modelos grandes
- **Almacenamiento**: 10GB+ para modelos y datos

## ğŸ“ Estructura del Proyecto

```
rag-microservice/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ endpoints.py      # Endpoints de la API
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py         # ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ prompt_manager.py # GestiÃ³n de prompts
â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â””â”€â”€ faiss_store.py    # AlmacÃ©n vectorial
â”‚   â”œâ”€â”€ langchain_wrapper.py  # IntegraciÃ³n LangChain
â”‚   â”œâ”€â”€ auto_ingest.py        # Auto-ingesta de PDFs
â”‚   â””â”€â”€ main.py               # AplicaciÃ³n principal
â”œâ”€â”€ pdfs/                     # Directorio de PDFs
â”œâ”€â”€ vectorstores/             # Ãndices vectoriales FAISS
â”œâ”€â”€ scripts/                  # Scripts de utilidad
â”œâ”€â”€ docker-compose.yml        # Docker para desarrollo
â”œâ”€â”€ docker-compose.production.yml # Docker para producciÃ³n
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”œâ”€â”€ test_microservice.py      # Suite de pruebas
â””â”€â”€ README.md                 # Esta documentaciÃ³n
```

## ğŸ”§ Troubleshooting

### Problemas Comunes

#### Error de Token de Hugging Face
```bash
# Verificar que el token estÃ© configurado
echo $HUGGINGFACEHUB_API_TOKEN

# O verificar en el archivo .env
grep HUGGINGFACEHUB_API_TOKEN .env
```

#### Memoria Insuficiente
```bash
# Usar modelos mÃ¡s ligeros
GENERATION_MODEL=google/flan-t5-small
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

#### PDFs No Se Procesan
```bash
# Verificar directorio de PDFs
ls -la pdfs/

# Forzar sincronizaciÃ³n
curl -X POST http://localhost:8000/documents/sync
```

#### Base Vectorial Corrupta
```bash
# Reconstruir Ã­ndices
curl -X POST http://localhost:8000/vectorstore/rebuild

# O eliminar y reconstruir
rm -rf vectorstores/
curl -X POST http://localhost:8000/vectorstore/rebuild
```

### Logs y DepuraciÃ³n

```bash
# Ver logs en tiempo real
docker-compose logs -f rag-microservice

# Ver logs especÃ­ficos
docker logs rag-microservice

# Verificar base de datos
python inspect_chunks.py
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™‹â€â™‚ï¸ Soporte

- **DocumentaciÃ³n**: `/docs` (FastAPI auto-docs)
- **Issues**: GitHub Issues
- **API Reference**: `/redoc`

---

**Â¿Necesitas ayuda?** Abre un issue o consulta la documentaciÃ³n automÃ¡tica en `/docs` una vez que el servicio estÃ© ejecutÃ¡ndose.